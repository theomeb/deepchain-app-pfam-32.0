{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "dcb5f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biodatasets import list_datasets, load_dataset\n",
    "from deepchain.models import MLP\n",
    "from deepchain.models.utils import (\n",
    "    confusion_matrix_plot,\n",
    "   # dataloader_from_numpy,\n",
    "    model_evaluation_accuracy,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "06e2dd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Start downloading pfam-32.0 dataset in biodatasets/.cache/pfam-32.0 ...\n",
      "dataset.csv: 267MB [01:52, 2.49MB/s]                              \n",
      "INFO: File pfam-32.0/dataset.csv downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/dataset.csv\n",
      "description.md: 8.00kB [00:00, 21.5kB/s]\n",
      "INFO: File pfam-32.0/description.md downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/description.md\n",
      "info.json: 8.00kB [00:00, 21.4kB/s]\n",
      "INFO: File pfam-32.0/info.json downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/info.json\n",
      "sequence_protbert_mean_embeddings.npy: 781MB [04:00, 3.41MB/s]                               \n",
      "INFO: File pfam-32.0/sequence_protbert_mean_embeddings.npy downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/sequence_protbert_mean_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# load pfam dataset\n",
    "pfam_dataset = load_dataset(\"pfam-32.0\", force=True)\n",
    "_, y = pfam_dataset.to_npy_arrays(input_names=[\"sequence\"], target_names=[\"family_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "314f0f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We take only the first 200000 sequences as we have only their embeddings available.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get embeddings and filter on available embeddings\n",
    "embeddings = pfam_dataset.get_embeddings(\"sequence\", \"protbert\", \"mean\")\n",
    "available_embeddings_len = len(embeddings)\n",
    "print(f\"We take only the first {available_embeddings_len} sequences as we have only their embeddings available.\")\n",
    "y = y[0][:available_embeddings_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c62821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "77f85bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15415 unique classes for family_id.\n"
     ]
    }
   ],
   "source": [
    "# process targets\n",
    "unique_classes = np.unique(y)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"There are {num_classes} unique classes for family_id.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "8be52bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: (200000,), [ 7066  3771 15329 ... 13940  1648  5782], 15415 classes\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit(unique_classes)\n",
    "targets = le.transform(y)\n",
    "print(f\"Targets: {targets.shape}, {targets}, {len(labels.classes_)} classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ca2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ffb81ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(embeddings, targets, test_size=0.3)\n",
    "\n",
    "train_dataloader = dataloader_from_numpy(X_train, y_train, batch_size=256)\n",
    "val_dataloader = dataloader_from_numpy(X_val, y_val, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7196e451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1024])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "590c629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "5fb339fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from deepchain.models.torch_model import TorchModel\n",
    "\n",
    "from pytorch_lightning.metrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "c94f3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamilyMLP(TorchModel):\n",
    "    \"\"\"Multi-layer perceptron model.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: int = 768, output_shape: int = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output = nn.Softmax if output_shape > 1 else nn.Sigmoid\n",
    "        self.loss = F.cross_entropy if output_shape > 1 else F.binary_cross_entropy\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Linear(input_shape, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines forward pass\"\"\"\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x).float()\n",
    "        return self._model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"training_step defined the train loop. It is independent of forward\"\"\"\n",
    "        x, y = batch\n",
    "        y_hat = self._model(x)\n",
    "        y = y.long()\n",
    "        #y = torch.unsqueeze(y, 1)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self._model(x)\n",
    "        y = y.long()\n",
    "        \n",
    "        loss = self.loss(y_hat, y)\n",
    "        \n",
    "        preds = torch.max(y_hat, dim=1)[1]\n",
    "        acc = accuracy(preds, y)\n",
    "        \n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        \"\"\"Save entire model with torch\"\"\"\n",
    "        torch.save(self._model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "043a9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = FamilyMLP(input_shape=X_train.shape[1], output_shape=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "6931fc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "57858b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FamilyMLP(\n",
       "  (_model): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=15415, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 4.3 M \n",
      "--------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.159    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707da84048ef4e2d82fda0e1e6bd9017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.fit(train_dataloader, val_dataloader, epochs=10, auto_lr_find=True, auto_scale_batch_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b757e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e209d5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(mlp(next(iter(train_dataloader))[0]), 1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "c9c64c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e92752cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "        False, False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        False,  True, False,  True,  True, False,  True,  True, False, False,\n",
       "         True,  True, False,  True, False,  True,  True, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        False,  True,  True, False, False,  True,  True, False,  True,  True,\n",
       "        False,  True,  True, False,  True, False,  True,  True, False, False,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        False, False, False, False, False, False,  True, False,  True, False,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False, False,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False,  True, False,  True,  True, False,  True,\n",
       "        False,  True, False, False, False,  True,  True, False,  True,  True,\n",
       "        False, False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        False, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        False,  True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True, False,  True, False, False,  True, False,\n",
       "         True,  True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False,  True,  True, False,  True,  True,\n",
       "         True, False, False,  True,  True, False])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(mlp(x), 1)[1] == y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531acba",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e0ae9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4f3712ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_accuracy(\n",
    "    dataloader: DataLoader, model\n",
    ") -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Make prediction for test data\n",
    "    Args:\n",
    "        dataloader: a torch dataloader containing dataset to be evaluated\n",
    "        model : a callable trained model with a predict method\n",
    "    \"\"\"\n",
    "    prediction, truth = [], []\n",
    "    for X, y in dataloader:\n",
    "        y_hat = torch.max(model.predict(X), 1)[1]\n",
    "        prediction += y_hat\n",
    "        truth += y.detach().numpy().flatten().tolist()\n",
    "\n",
    "    prediction, truth = np.array(prediction), np.array(truth)\n",
    "\n",
    "    acc_score = accuracy_score(truth, prediction)\n",
    "    print(f\" Test :  accuracy score : {acc_score:0.2f}\")\n",
    "\n",
    "    return prediction, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "26db0e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test :  accuracy score : 0.46\n"
     ]
    }
   ],
   "source": [
    "prediction, truth = model_evaluation_accuracy(train_dataloader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2672ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "992b474b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1a9495f9c5fc493c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1a9495f9c5fc493c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b2862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
