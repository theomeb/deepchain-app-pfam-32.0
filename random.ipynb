{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8677917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biodatasets import list_datasets, load_dataset\n",
    "from deepchain.models import MLP\n",
    "from deepchain.models.utils import (\n",
    "    confusion_matrix_plot,\n",
    "    dataloader_from_numpy,\n",
    "    model_evaluation_accuracy,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50462f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Start downloading pfam-32.0 dataset in biodatasets/.cache/pfam-32.0 ...\n",
      "dataset.csv: 267MB [03:54, 1.19MB/s]                              \n",
      "INFO: File pfam-32.0/dataset.csv downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/dataset.csv\n",
      "description.md: 8.00kB [00:00, 13.5kB/s]\n",
      "INFO: File pfam-32.0/description.md downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/description.md\n",
      "info.json: 8.00kB [00:00, 18.8kB/s]\n",
      "INFO: File pfam-32.0/info.json downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/info.json\n",
      "sequence_protbert_mean_embeddings.npy: 781MB [04:34, 2.98MB/s]                               \n",
      "INFO: File pfam-32.0/sequence_protbert_mean_embeddings.npy downloaded from Google Bucket 'deepchain-datasets-public' at biodatasets/.cache/pfam-32.0/sequence_protbert_mean_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# load pfam dataset\n",
    "pfam_dataset = load_dataset(\"pfam-32.0\", force=True)\n",
    "_, y = pfam_dataset.to_npy_arrays(input_names=[\"sequence\"], target_names=[\"family_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2daca8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We take only the first 200000 sequences as we have only their embeddings available.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get embeddings and filter on available embeddings\n",
    "embeddings = pfam_dataset.get_embeddings(\"sequence\", \"protbert\", \"mean\")\n",
    "available_embeddings_len = len(embeddings)\n",
    "print(f\"We take only the first {available_embeddings_len} sequences as we have only their embeddings available.\")\n",
    "y = y[0][:available_embeddings_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8687b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adeea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15415 unique classes for family_id.\n"
     ]
    }
   ],
   "source": [
    "# process targets\n",
    "unique_classes = np.unique(y)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"There are {num_classes} unique classes for family_id.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf7664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: (200000,), [ 7066  3771 15329 ... 13940  1648  5782], 15415 classes\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit(unique_classes)\n",
    "targets = le.transform(y)\n",
    "print(f\"Targets: {targets.shape}, {targets}, {len(labels.classes_)} classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe4222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11de3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(embeddings, targets, test_size=0.2)\n",
    "\n",
    "train_dataloader = dataloader_from_numpy(X_train, y_train, batch_size=256)\n",
    "val_dataloader = dataloader_from_numpy(X_val, y_val, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06428577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53a0edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7770efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from deepchain.models.torch_model import TorchModel\n",
    "\n",
    "from pytorch_lightning.metrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc8db5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamilyMLP(TorchModel):\n",
    "    \"\"\"Multi-layer perceptron model.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: int = 768, output_shape: int = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output = nn.Softmax if output_shape > 1 else nn.Sigmoid\n",
    "        self.loss = F.cross_entropy if output_shape > 1 else F.binary_cross_entropy\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Linear(input_shape, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines forward pass\"\"\"\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x).float()\n",
    "        return self._model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"training_step defined the train loop. It is independent of forward\"\"\"\n",
    "        x, y = batch\n",
    "        y_hat = self._model(x)\n",
    "        y = y.long()\n",
    "        #y = torch.unsqueeze(y, 1)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self._model(x)\n",
    "        y = y.long()\n",
    "        \n",
    "        loss = self.loss(y_hat, y)\n",
    "        \n",
    "        preds = torch.max(y_hat, dim=1)[1]\n",
    "        acc = accuracy(preds, y)\n",
    "        \n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        \"\"\"Save entire model with torch\"\"\"\n",
    "        torch.save(self._model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930bbfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = FamilyMLP(input_shape=X_train.shape[1], output_shape=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b132aab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62465651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FamilyMLP(\n",
       "  (_model): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=15415, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cef8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp._model = torch.load(\"checkpoint/family_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0649cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 4.3 M \n",
      "--------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.159    Total estimated model params size (MB)\n",
      "/Users/theomeborckinstadeep/miniconda3/envs/deepchain-env/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theomeborckinstadeep/miniconda3/envs/deepchain-env/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c615896df745c49996b20f06d114a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.fit(train_dataloader, val_dataloader, epochs=10, auto_lr_find=True, auto_scale_batch_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "c7dc8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save_model(\"family_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5d2e79f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(mlp(next(iter(train_dataloader))[0]), 1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "5a86b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "4cb5309d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "         True,  True,  True, False,  True,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        False,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True, False, False,  True, False,  True,  True, False,  True,\n",
       "         True, False,  True,  True,  True, False, False,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
       "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        False,  True, False,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "         True, False,  True,  True,  True, False, False,  True,  True,  True,\n",
       "         True,  True, False, False, False,  True, False,  True, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False,  True,  True,  True,  True, False,\n",
       "        False,  True,  True, False,  True,  True])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(mlp(x), 1)[1] == y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a788d2",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "06d2c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "90580e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_accuracy(\n",
    "    dataloader: DataLoader, model\n",
    ") -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Make prediction for test data\n",
    "    Args:\n",
    "        dataloader: a torch dataloader containing dataset to be evaluated\n",
    "        model : a callable trained model with a predict method\n",
    "    \"\"\"\n",
    "    prediction, truth = [], []\n",
    "    for X, y in dataloader:\n",
    "        y_hat = torch.max(model.predict(X), 1)[1]\n",
    "        prediction += y_hat\n",
    "        truth += y.detach().numpy().flatten().tolist()\n",
    "\n",
    "    prediction, truth = np.array(prediction), np.array(truth)\n",
    "\n",
    "    acc_score = accuracy_score(truth, prediction)\n",
    "    print(f\" Test :  accuracy score : {acc_score:0.2f}\")\n",
    "\n",
    "    return prediction, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "c0f15877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test :  accuracy score : 0.73\n"
     ]
    }
   ],
   "source": [
    "prediction, truth = model_evaluation_accuracy(train_dataloader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "9a846e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test :  accuracy score : 0.66\n"
     ]
    }
   ],
   "source": [
    "prediction, truth = model_evaluation_accuracy(val_dataloader, mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8823a5",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3cb45d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f5024865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(le, 'label_encoder.joblib')\n",
    "label_encoder = joblib.load('label_encoder.joblib')\n",
    "label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3f9461b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(sequences: List[str]):\n",
    "    \"\"\"Return a list of all proteins score\"\"\"\n",
    "\n",
    "    #x_embedding = self.transformer.compute_embeddings(sequences)[\"mean\"]\n",
    "    x_embedding = embeddings[:len(sequences)]\n",
    "    \n",
    "    y_hat = mlp(torch.tensor(x_embedding))\n",
    "    preds = torch.max(y_hat, dim=1)[1]\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    \n",
    "    family_preds = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    family_list = [{\"family_id\": family_pred} for family_pred in family_preds]\n",
    "\n",
    "    return family_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "bd24b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'family_id': 'GMC_oxred_C'}, {'family_id': 'DUF2887'}]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\n",
    "        \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\",\n",
    "        \"KALTARQQEVFDLIRDHISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\",\n",
    "    ]\n",
    "compute_scores(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "dfe25946",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1a9495f9c5fc493c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1a9495f9c5fc493c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c89265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}